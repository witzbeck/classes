{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armijo Line-Search Rule\n",
    "\n",
    "The successive reduction rule suitably modified to eliminate theoretical convergence difficulty\n",
    "\n",
    "Featuring 'Newton's Method' and 'Steepest Decent' applied to a logistic regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and definitions\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "from pandas import concat as cc\n",
    "\n",
    "#Initial values\n",
    "beta0,beta1 = 5,-2\n",
    "init_p = [beta0,beta1]\n",
    "\n",
    "#Data\n",
    "hours = [0.50,0.75,1.00,1.25,1.50,1.75,1.75,2.00,2.25,2.50,2.75,3.00,3.25,3.50,4.00,4.25,4.50,4.75,5.00,5.50]\n",
    "passed = [0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1]\n",
    "\n",
    "#Line search parameters\n",
    "s,beta,sigma = 1,0.5,0.1\n",
    "\n",
    "#Number of iterations\n",
    "n_iter= range(5)\n",
    "\n",
    "#logreg prob\n",
    "def p(x,beta0=beta0,beta1=beta1):\n",
    "    ex = beta0 + beta1*x\n",
    "    px = 1/(1+np.exp(-ex))\n",
    "    return px\n",
    "\n",
    "#Function to be minimized/Loglikelihood\n",
    "def loglik(x_list=hours,y_list=passed,beta0=beta0,beta1=beta1):\n",
    "    cumsum = 0\n",
    "    for i,x in enumerate(x_list):\n",
    "        cumsum += y_list[i]*np.log(p(x,beta0=beta0,beta1=beta1)) \n",
    "        cumsum += (1-y_list[i])*np.log(1-p(x,beta0=beta0,beta1=beta1))\n",
    "    return cumsum\n",
    "\n",
    "#Gradient of loglikelihood function\n",
    "def loglik_grad(x_list=hours,y_list=passed,beta0=beta0,beta1=beta1):\n",
    "    dl_db0 = 0\n",
    "    dl_db1 = 0\n",
    "\n",
    "    for i,x in enumerate(x_list):\n",
    "        dl_db0 += (y_list[i]-p(x,beta0=beta0,beta1=beta1))\n",
    "        dl_db1 += (y_list[i]-(x*p(x,beta0=beta0,beta1=beta1)))\n",
    "    \n",
    "    return np.array([dl_db0,dl_db1])\n",
    "\n",
    "def loglik_hess(x_list=hours,y_list=passed,beta0=beta0,beta1=beta1):\n",
    "    d2_db02 = 0\n",
    "    d2_db0b1 = 0\n",
    "    d2_db12 = 0\n",
    "\n",
    "    for i,x in enumerate(x_list):\n",
    "        d2_db02 += (y_list[i]-(p(x,beta0=beta0,beta1=beta1)*(1-p(x,beta0=beta0,beta1=beta1))))\n",
    "        d2_db0b1 += (y_list[i]-(x*p(x,beta0=beta0,beta1=beta1)*(1-p(x,beta0=beta0,beta1=beta1))))\n",
    "        d2_db12 += (y_list[i]-((x**2)*p(x,beta0=beta0,beta1=beta1)*(1-p(x,beta0=beta0,beta1=beta1))))\n",
    "    return np.array([[d2_db02,d2_db0b1],[d2_db0b1,d2_db12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Newton's Method\n",
    "def newton(fm=loglik,fm_grad=loglik_grad,fm_hess=loglik_hess,\n",
    "                init_p=[beta0,beta1],n_iter=n_iter,\n",
    "                s=s,beta=beta,sigma=sigma):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        fm: function to minimize\n",
    "        fm_grad: gradient of fm\n",
    "        fm_hess: hessian of fm\n",
    "        init_p: initial point\n",
    "        n_iter: number of iterations\n",
    "        s,beta,sigma: line search parameters\n",
    "    \"\"\"\n",
    "\n",
    "    #Lists to store function in/out values\n",
    "    points_list = []\n",
    "    points_list.append(init_p)\n",
    "    fm_list = []\n",
    "    fm_list.append(fm(beta0=init_p[0],beta1=init_p[1]))\n",
    "    iter_list = []\n",
    "\n",
    "    for n in n_iter:\n",
    "        cur_point = points_list[-1]\n",
    "        beta0,beta1 = cur_point[0],cur_point[1]\n",
    "\n",
    "        grad = loglik_grad(beta0=beta0,beta1=beta1)\n",
    "        hess = loglik_hess(beta0=beta0,beta1=beta1)\n",
    "        inv_hess = np.linalg.inv(hess)\n",
    "        delt = np.matmul(inv_hess,grad)\n",
    "\n",
    "        new_p = [cur_point[i]-delt[i] for i in range(len(cur_point))]\n",
    "        points_list.append(new_p)\n",
    "        fm_list.append(fm(beta0=new_p[0],beta1=new_p[1]))\n",
    "\n",
    "        #Saving iteration values in dicts for later display\n",
    "        iter = {\n",
    "                \"Method\":\"Newton's\",\n",
    "                \"Step#\":n+1,\n",
    "                \"WhileIter\":\"na\",\n",
    "                \"CurPoint\":[round(a,3) for a in new_p],\n",
    "                \"F()\":fm_list[-1],\n",
    "            }\n",
    "        iter_list.append(iter)\n",
    "        #print(iter)\n",
    "    return iter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steepest Ascent\n",
    "def armijostep(fm=loglik,fm_grad=loglik_grad,\n",
    "                init_p=[beta0,beta1],n_iter=n_iter,\n",
    "                s=s,beta=beta,sigma=sigma):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        fm: function to minimize\n",
    "        fm_grad: gradient of fm\n",
    "        init_p: initial point\n",
    "        n_iter: number of iterations\n",
    "        s,beta,sigma: line search parameters\n",
    "    \"\"\"\n",
    "    #Number of dimensions determined by length of initiating vector\n",
    "    n_dim = len(init_p)\n",
    "\n",
    "    #Lists to store function in/out values\n",
    "    points_list = []\n",
    "    points_list.append(init_p)\n",
    "    fm_list = []\n",
    "    fm_list.append(fm(beta0=init_p[0],beta1=init_p[1]))\n",
    "    iter_list = []\n",
    "\n",
    "    for step in n_iter:\n",
    "        #Each loop is initialized using the preceding output\n",
    "        cur_p = points_list[-1]\n",
    "        last_fm = fm_list[-1]\n",
    "        \n",
    "        #The current point is run through the gradient function\n",
    "        #   We want the direction of steepest descent,\n",
    "        #   therefore we want the opposite of each value in the gradient\n",
    "        grad = fm_grad(beta0=cur_p[0],beta1=cur_p[1])\n",
    "        #d = [-m for m in grad]\n",
    "\n",
    "        #While loop is initialized with beta**k = 1\n",
    "        k = 0\n",
    "        step_size = [grad[i]*s*sigma*(beta**k) for i in range(n_dim)]\n",
    "        trial_p = [cur_p[j] + step_size[j] for j in range(n_dim)]\n",
    "        \n",
    "        #Each loop, if the function returns a larger value, \n",
    "        #the step size at each point is reduced by a factor of beta, then rerun\n",
    "        while fm(beta0=trial_p[0],beta1=trial_p[1]) < last_fm:\n",
    "            k += 1\n",
    "            step_size = [grad[i]*s*sigma*(beta**k) for i in range(n_dim)]\n",
    "            trial_p = [cur_p[j] + step_size[j] for j in range(n_dim)]\n",
    "\n",
    "        #Upon reaching smaller fm value, the parameters are appended to lists\n",
    "        points_list.append(trial_p)\n",
    "        fm_list.append(fm(beta0=trial_p[0],beta1=trial_p[1]))\n",
    "\n",
    "        #Saving iteration values in dicts for later display\n",
    "        iter = {\n",
    "                \"Method\":\"Steepest\",\n",
    "                \"Step#\":step+1,\n",
    "                \"WhileIter\":k,\n",
    "                \"CurPoint\":[round(a,3) for a in trial_p],\n",
    "                \"F()\":fm_list[-1],\n",
    "            }\n",
    "        iter_list.append(iter)\n",
    "        #print(iter)\n",
    "    return iter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method  Step# WhileIter         CurPoint         F()\n",
      "0  Steepest      1        49      [5.0, -2.0]  -48.918024\n",
      "1  Steepest      2        51      [5.0, -2.0]  -48.918024\n",
      "2  Steepest      3        51      [5.0, -2.0]  -48.918024\n",
      "3  Steepest      4        51      [5.0, -2.0]  -48.918024\n",
      "4  Steepest      5        51      [5.0, -2.0]  -48.918024\n",
      "0  Newton's      1        na  [5.434, -2.831]  -69.969386\n",
      "1  Newton's      2        na  [5.682, -3.595]  -92.443039\n",
      "2  Newton's      3        na  [5.343, -3.833] -102.076926\n",
      "3  Newton's      4        na  [4.258, -3.366]  -92.699014\n",
      "4  Newton's      5        na  [2.917, -2.702]  -78.546203\n"
     ]
    }
   ],
   "source": [
    "#Dataframe for results display\n",
    "steepest = armijostep()\n",
    "newtons = newton()\n",
    "\n",
    "steep_df = df.from_records(steepest)\n",
    "newt_df = df.from_records(newtons)\n",
    "\n",
    "result = cc([steep_df,newt_df])\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78706c31b69ede7c2c34732072d004318d4815f038b3d91e252f917f8ecd20eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('math857': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
